{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"New to cognee?","text":"<p>The getting started guide covers adding a cognee data store to your AI app, sending data, identifying users, extracting actions and insights, and interconnecting separate datasets.</p> <p>Get started</p>"},{"location":"#ingest-data","title":"Ingest Data","text":"<p>Learn how to manage the ingestion of events, customer data, or third-party data for use with cognee.</p> <p>Explore</p>"},{"location":"#tasks-and-pipelines","title":"Tasks and Pipelines","text":"<p>Analyze and enrich your data and improve LLM answers with a series of tasks and pipelines.</p> <p>Learn about tasks</p>"},{"location":"#api","title":"API","text":"<p>Push or pull data to build custom functionality or create bespoke views for your business needs.</p> <p>Explore</p>"},{"location":"#resources","title":"Resources","text":""},{"location":"#resources_1","title":"Resources","text":"<ul> <li>Research</li> <li>Community</li> </ul>"},{"location":"api_reference/","title":"Cognee API Reference","text":""},{"location":"api_reference/#overview","title":"Overview","text":"<p>The Cognee API provides a set of endpoints for managing datasets, performing cognitive tasks, and configuring various settings in the system. The API is built on FastAPI and includes multiple routes to handle different functionalities. This reference outlines the available endpoints and their usage.</p>"},{"location":"api_reference/#base-url","title":"Base URL","text":"<p>The base URL for all API requests is determined by the server's deployment environment. Typically, this will be:</p> <ul> <li>Development: <code>http://localhost:8000</code></li> <li>Production: Depending on your server setup.</li> </ul>"},{"location":"api_reference/#endpoints","title":"Endpoints","text":""},{"location":"api_reference/#1-root","title":"1. Root","text":"<ul> <li>URL: <code>/</code></li> <li>Method: <code>GET</code></li> <li>Auth Required: No</li> <li>Description: Root endpoint that returns a welcome message.</li> </ul> <p>Response:   <pre><code>{\n  \"status\": 200,\n  \"body\": {\n    \"message\": \"Hello, World, I am alive!\"\n  }\n}\n</code></pre></p>"},{"location":"api_reference/#2-health-check","title":"2. Health Check","text":"<ul> <li>URL: <code>/health</code></li> <li>Method: <code>GET</code></li> <li>Auth Required: No</li> <li>Description: Health check endpoint that returns the server status.</li> </ul> <p>Response:   <pre><code>{\n  \"status\": 200\n}\n</code></pre></p>"},{"location":"api_reference/#3-get-datasets","title":"3. Get Datasets","text":"<ul> <li>URL: <code>/datasets</code></li> <li>Method: <code>GET</code></li> <li>Auth Required: No</li> <li>Description: Retrieve a list of available datasets.</li> </ul> <p>Response:   <pre><code>{\n  \"status\": 200,\n  \"body\": [\n    {\n      \"id\": \"dataset_id_1\",\n      \"name\": \"Dataset Name 1\",\n      \"description\": \"Description of Dataset 1\",\n      ...\n    },\n    ...\n  ]\n}\n</code></pre></p>"},{"location":"api_reference/#4-delete-dataset","title":"4. Delete Dataset","text":"<ul> <li>URL: <code>/datasets/{dataset_id}</code></li> <li>Method: <code>DELETE</code></li> <li>Auth Required: No</li> <li>Description: Delete a specific dataset by its ID.</li> </ul> <p>Path Parameters:   - <code>dataset_id</code>: The ID of the dataset to delete.</p> <p>Response:   <pre><code>{\n  \"status\": 200\n}\n</code></pre></p>"},{"location":"api_reference/#5-get-dataset-graph","title":"5. Get Dataset Graph","text":"<ul> <li>URL: <code>/datasets/{dataset_id}/graph</code></li> <li>Method: <code>GET</code></li> <li>Auth Required: No</li> <li>Description: Retrieve the graph visualization URL for a specific dataset.</li> </ul> <p>Path Parameters:   - <code>dataset_id</code>: The ID of the dataset.</p> <p>Response:   <pre><code>\"http://example.com/path/to/graph\"\n</code></pre></p>"},{"location":"api_reference/#6-get-dataset-data","title":"6. Get Dataset Data","text":"<ul> <li>URL: <code>/datasets/{dataset_id}/data</code></li> <li>Method: <code>GET</code></li> <li>Auth Required: No</li> <li>Description: Retrieve data associated with a specific dataset.</li> </ul> <p>Path Parameters:   - <code>dataset_id</code>: The ID of the dataset.</p> <p>Response:   <pre><code>{\n  \"status\": 200,\n  \"body\": [\n    {\n      \"data_id\": \"data_id_1\",\n      \"content\": \"Data content here\",\n      ...\n    },\n    ...\n  ]\n}\n</code></pre></p>"},{"location":"api_reference/#7-get-dataset-status","title":"7. Get Dataset Status","text":"<ul> <li>URL: <code>/datasets/status</code></li> <li>Method: <code>GET</code></li> <li>Auth Required: No</li> <li>Description: Retrieve the status of one or more datasets.</li> </ul> <p>Query Parameters:   - <code>dataset</code>: A list of dataset IDs to check status for.</p> <p>Response:   <pre><code>{\n  \"status\": 200,\n  \"body\": {\n    \"dataset_id_1\": \"Status 1\",\n    \"dataset_id_2\": \"Status 2\",\n    ...\n  }\n}\n</code></pre></p>"},{"location":"api_reference/#8-get-raw-data","title":"8. Get Raw Data","text":"<ul> <li>URL: <code>/datasets/{dataset_id}/data/{data_id}/raw</code></li> <li>Method: <code>GET</code></li> <li>Auth Required: No</li> <li>Description: Retrieve the raw data file for a specific data entry in a dataset.</li> </ul> <p>Path Parameters:   - <code>dataset_id</code>: The ID of the dataset.   - <code>data_id</code>: The ID of the data entry.</p> <p>Response: Raw file download.</p>"},{"location":"api_reference/#9-add-data","title":"9. Add Data","text":"<ul> <li>URL: <code>/add</code></li> <li>Method: <code>POST</code></li> <li>Auth Required: No</li> <li>Description: Add new data to a dataset. The data can be uploaded from a file or a URL.</li> </ul> <p>Form Parameters:   - <code>datasetId</code>: The ID of the dataset to add data to.   - <code>data</code>: A list of files to upload.</p> <p>Request <pre><code>{\n  \"dataset_id\": \"ID_OF_THE_DATASET_TO_PUT_DATA_IN\", // Optional, we use \"main\" as default.\n  \"files\": File[]\n}\n</code></pre></p> <p>Response:   <pre><code>{\n  \"status\": 200\n}\n</code></pre></p>"},{"location":"api_reference/#10-cognify","title":"10. Cognify","text":"<ul> <li>URL: <code>/cognify</code></li> <li>Method: <code>POST</code></li> <li>Auth Required: No</li> <li>Description: Perform cognitive processing on the specified datasets.</li> </ul> <p>Request Body:   <pre><code>{\n  \"datasets\": [\"ID_OF_THE_DATASET_1\", \"ID_OF_THE_DATASET_2\", ...]\n}\n</code></pre></p> <p>Response:   <pre><code>{\n  \"status\": 200\n}\n</code></pre></p>"},{"location":"api_reference/#11-search","title":"11. Search","text":"<ul> <li>URL: <code>/search</code></li> <li>Method: <code>POST</code></li> <li>Auth Required: No</li> <li>Description: Search for nodes in the graph based on the provided query parameters.</li> </ul> <p>Request Body:   <pre><code>{\n  \"searchType\": \"INSIGHTS\", // Or \"SUMMARIES\" or \"CHUNKS\"\n  \"query\": \"QUERY_TO_MATCH_DATA\"\n}\n</code></pre></p> <p>Response</p> <p>For \"INSIGHTS\" search type:   <pre><code>{\n  \"status\": 200,\n  \"body\": [[\n    { \"name\" \"source_node_name\" },\n    { \"relationship_name\" \"between_nodes_relationship_name\" },\n    { \"name\" \"target_node_name\" },\n  ]]\n}\n</code></pre></p> <p>For \"SUMMARIES\" search type:     <pre><code>{\n  \"status\": 200,\n  \"body\": [\n    { \"text\" \"summary_text\" },\n    { \"text\" \"summary_text\" },\n    { \"text\" \"summary_text\" },\n    ...\n  ]\n}\n</code></pre></p> <p>For \"CHUNKS\" search type:   <pre><code>{\n  \"status\": 200,\n  \"body\": [\n    { \"text\" \"chunk_text\" },\n    { \"text\" \"chunk_text\" },\n    { \"text\" \"chunk_text\" },\n    ...\n  ]\n}\n</code></pre></p>"},{"location":"api_reference/#12-get-settings","title":"12. Get Settings","text":"<ul> <li>URL: <code>/settings</code></li> <li>Method: <code>GET</code></li> <li>Auth Required: No</li> <li>Description: Retrieve the current system settings.</li> </ul> <p>Response:   <pre><code>{\n  \"status\": 200,\n  \"body\": {\n    \"llm\": {...},\n    \"vectorDB\": {...},\n    ...\n  }\n}\n</code></pre></p>"},{"location":"api_reference/#13-save-settings","title":"13. Save Settings","text":"<ul> <li>URL: <code>/settings</code></li> <li>Method: <code>POST</code></li> <li>Auth Required: No</li> <li>Description: Save new settings for the system, including LLM and vector DB configurations.</li> </ul> <p>Request Body:   - <code>llm</code>: Optional. The configuration for the LLM provider.   - <code>vectorDB</code>: Optional. The configuration for the vector database provider.</p> <p>Response:   <pre><code>{\n  \"status\": 200\n}\n</code></pre></p>"},{"location":"conceptual_overview/","title":"Conceptual Overview - cognee","text":""},{"location":"conceptual_overview/#introduction","title":"Introduction","text":"<p>What is cognee?</p> <p>cognee is a data processing framework that enables LLMs to produce deterministic and traceable outputs.</p> <p>cognee assists developers in introducing greater predictability and management into their Retrieval-Augmented Generation (RAG) workflows through the use of graph architectures, vector stores, and auto-optimizing pipelines.</p> <p>Displaying information as a graph is the clearest way to grasp the content of your documents. Crucially, graphs allow systematic navigation and extraction of data from documents based on their hierarchy.</p>"},{"location":"conceptual_overview/#core-concepts","title":"Core Concepts","text":""},{"location":"conceptual_overview/#concept-1-data-pipelines","title":"Concept 1: Data Pipelines","text":"<p>Most of the data we provide to a system can be categorized as unstructured, semi-structured, or structured. Rows from a database would belong to structured data, jsons to semi-structured data, and logs that we input into the system could be considered unstructured. To organize and process this data, we need to ensure we have custom loaders for all data types, which can help us unify and organize it properly.</p> <p></p> Data Pipeline Example <p>In the example above, we have a pipeline in which data has been imported from various sources, normalized, and stored in a database. Relevant identifiers and relationships between the data are also created in this process. To create an effective data pipeline for processing various types of data\u2014structured, semi-structured, and unstructured\u2014it\u2019s crucial to understand each type's specific handling and processing needs. Let's expand on the concepts involved in setting up such a data pipeline.</p> <p>Data Types and Their Handling - Structured Data: This includes data that adheres to a fixed schema, such as rows in a relational database or data in CSV files. The processing of structured data typically involves SQL queries for extraction, transformations through simple functions or procedures, and loading into destination tables or databases.</p> <ul> <li> <p>Semi-structured Data: JSON files, XML, or even some APIs' data fit this category. These data types don't have a rigid schema but have some organizational properties that can be exploited. Semi-structured data often requires parsers that can navigate its structure (like trees for XML or key-value pairs for JSON) to extract necessary information. Libraries such as json in Python or lxml for XML handling can be very useful here.</p> </li> <li> <p>Unstructured Data: This category includes text files, logs, or even images and videos. </p> </li> </ul>"},{"location":"conceptual_overview/#concept-2-data-enrichment-with-llms","title":"Concept 2: Data Enrichment with LLMs","text":"<p>LLMs are adept at processing unstructured data. They can easily extract summaries, keywords, and other useful information from documents. We use function calling with Pydantic models to extract information from the unstructured data.</p> <p></p> Data Enrichment Example <p>We decompose the loaded content into graphs, allowing us to more precisely map out the relationships between entities and concepts.</p>"},{"location":"conceptual_overview/#concept-3-graphs","title":"Concept 3: Graphs","text":"<p>Knowledge graphs simply map out knowledge, linking specific facts and their connections.  When Large Language Models (LLMs) process text, they infer these links, leading to occasional inaccuracies due to their probabilistic nature. </p> <p>Clearly defined relationships enhance their accuracy.  </p> <p>This structured approach can extend beyond concepts to document layouts, pages, or other organizational schemas.</p> <p></p> Graph Structure"},{"location":"conceptual_overview/#concept-4-vector-and-graph-retrieval","title":"Concept 4: Vector and Graph Retrieval","text":"<p>Cognee lets you use multiple vector and graph retrieval methods to find the most relevant information.</p> <p>Learn more?</p> <p>Check out learning materials to see how you can use these methods in your projects.</p>"},{"location":"conceptual_overview/#concept-5-auto-optimizing-pipelines","title":"Concept 5: Auto-Optimizing Pipelines","text":"<p>Integrating knowledge graphs into Retrieval-Augmented Generation (RAG) pipelines leads to an intriguing outcome: the system's adeptness at contextual understanding allows it to be evaluated in a way Machine Learning (ML) engineers are accustomed to. </p> <p>This involves bombarding the RAG system with hundreds of synthetic questions, enabling the knowledge graph to evolve and refine its context autonomously over time. </p> <p>This method paves the way for developing self-improving memory engines that can adapt to new data and user feedback.</p>"},{"location":"conceptual_overview/#architecture-overview","title":"Architecture Overview","text":"<p>A high-level diagram of cognee's architecture, illustrating the main components and their interactions.</p> <p></p> Architecture <p>Main components:</p> <ul> <li>Data Pipelines: Responsible for ingesting, processing, and transforming data from various sources.</li> <li>LLMs: Large Language Models that process unstructured data and generate text.</li> <li>Graph Store: Knowledge graphs that represent relationships between entities and concepts.</li> <li>Vector Store: Database that stores vector representations of data for efficient retrieval.</li> <li>Search: Retrieves relevant information from the knowledge graph and vector stores.</li> </ul>"},{"location":"conceptual_overview/#how-it-fits-into-your-projects","title":"How It Fits Into Your Projects","text":"<p>How cognee fits into your projects</p> <p>cognee is a self-contained library that simplifies the process of loading and structuring data in LLMs.</p> <p>By integrating cognee into your data pipelines, you can leverage the power of LLMs, knowledge graphs, and vector retrieval to create accurate and explainable AI solutions. cognee provides a self-contained library that simplifies the process of loading and structuring LLM context, enabling you to create accurate and explainable AI solutions.</p>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#configure-vector-and-graph-stores","title":"\ud83d\ude80 Configure Vector and Graph Stores","text":"<p>You can configure the vector and graph stores using the environment variables in your .env file or programmatically. We use Pydantic Settings</p> <p>We have a global configuration object (cognee.config) and individual configurations on pipeline and data store levels</p> <p>Check available configuration options: <pre><code>from cognee.infrastructure.databases.vector import get_vectordb_config\nfrom cognee.infrastructure.databases.graph.config import get_graph_config\nfrom cognee.infrastructure.databases.relational import get_relational_config\nfrom cognee.infrastructure.llm.config import get_llm_config\nprint(get_vectordb_config().to_dict())\nprint(get_graph_config().to_dict())\nprint(get_relational_config().to_dict())\nprint(get_llm_config().to_dict())\n</code></pre></p> <p>Setting the environment variables in your .env file, and Pydantic will pick them up:</p> <p><pre><code>GRAPH_DATABASE_PROVIDER = 'lancedb'\n</code></pre> Otherwise, you can set the configuration yourself:</p> <pre><code>cognee.config.set_llm_provider('ollama')\n</code></pre>"},{"location":"configuration/#getting-started-with-local-models","title":"\ud83d\ude80 Getting Started with Local Models","text":"<p>You'll need to run the local model on your machine or use one of the providers hosting the model.</p> <p>We had some success with mixtral, but 7b models did not work well. We recommend using mixtral for now.</p>"},{"location":"configuration/#ollama","title":"Ollama","text":"<p>Set up Ollama by following instructions on Ollama website</p> <p>Set the environment variable in your .env to use the model</p> <p><pre><code>LLM_PROVIDER = 'ollama'\n</code></pre> Otherwise, you can set the configuration for the model:</p> <p><pre><code>cognee.config.set_llm_provider('ollama')\n</code></pre> You can also set the HOST and model name:</p> <pre><code>cognee.config.set_llm_endpoint(\"http://localhost:11434/v1\")\ncognee.config.set_llm_model(\"mistral:instruct\")\n</code></pre>"},{"location":"configuration/#anyscale","title":"Anyscale","text":"<p><pre><code>LLM_PROVIDER = 'custom'\n</code></pre> Otherwise, you can set the configuration for the model:</p> <p><pre><code>cognee.config.set_llm_provider('custom')\n</code></pre> You can also set the HOST  and model name: <pre><code>LLM_MODEL = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\nLLM_ENDPOINT = \"https://api.endpoints.anyscale.com/v1\"\nLLM_API_KEY = \"your_api_key\"\n</code></pre></p> <p>You can set the same way HOST and model name for any other provider that has an API endpoint.</p>"},{"location":"data_engineering_llm_ops/","title":"Data Engineering and LLMOps","text":"<p>This is a work in progress and any feedback is welcome</p>"},{"location":"data_engineering_llm_ops/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Data Engineering</li> <li>Large Language Model Operations (LLM Ops)</li> </ol>"},{"location":"data_engineering_llm_ops/#data-engineering","title":"Data Engineering","text":"<p>Data Engineering focuses on managing and analyzing big data. It revolves around five key aspects:</p>"},{"location":"data_engineering_llm_ops/#volume","title":"Volume","text":"<p>The size and amount of data that companies manage and analyze.</p>"},{"location":"data_engineering_llm_ops/#value","title":"Value","text":"<p>The insights and patterns derived from data that lead to business benefits.</p>"},{"location":"data_engineering_llm_ops/#variety","title":"Variety","text":"<p>The diversity of data types, including unstructured, semi-structured, and raw data.</p>"},{"location":"data_engineering_llm_ops/#velocity","title":"Velocity","text":"<p>The speed at which data is received, stored, and managed.</p>"},{"location":"data_engineering_llm_ops/#veracity","title":"Veracity","text":"<p>The accuracy or truthfulness of data.</p>"},{"location":"data_engineering_llm_ops/#large-language-model-operations-llm-ops","title":"Large Language Model Operations (LLM Ops)","text":"<p>The emerging field of Large Language Model Operations (LLM Ops) inherits many practices from data engineering. LLM Ops involves the deployment, monitoring, and maintenance of systems using LLMs to manage and build new generation of AI powered applications. </p> <p>For more in-depth information on LLM Ops, see Resource Name.</p>"},{"location":"data_ingestion/","title":"How data ingestion with cognee works","text":""},{"location":"data_ingestion/#why-bother-with-data-ingestion","title":"Why bother with data ingestion?","text":"<p>In order to use cognee, you need to ingest data into the cognee data store.  This data can be events, customer data, or third-party data. </p> <p>In order to build reliable models and pipelines, we need to structure and process various types of datasets and data sources in the same way. Some of the operations like normalization, deduplication, and data cleaning are common across all data sources.</p> <p>This is where cognee comes in. It provides a unified interface to ingest data from various sources and process it in a consistent way. For this we use dlt (Data Loading Tool) which is a part of cognee infrastructure.</p>"},{"location":"data_ingestion/#example","title":"Example","text":"<p>Let's say you have a dataset of customer reviews in a PDF file. You want to ingest this data into cognee and use it to train a model.</p> <p>You can use the following code to ingest the data:</p> <pre><code>dataset_name = \"artificial_intelligence\"\n\nai_text_file_path = os.path.join(pathlib.Path(__file__).parent, \"test_data/artificial-intelligence.pdf\")\nawait cognee.add([ai_text_file_path], dataset_name)\n</code></pre> <p>cognee uses dlt to ingest the data and allows you to use:</p> <ol> <li>SQL databases. Supports PostgreSQL, MySQL, MS SQL Server, BigQuery, Redshift, and more.</li> <li>REST API generic source. Loads data from REST APIs using declarative configuration.</li> <li>OpenAPI source generator. Generates a source from an OpenAPI 3.x spec using the REST API source.</li> <li>Cloud and local storage. Retrieves data from AWS S3, Google Cloud Storage, Azure Blob Storage, local files, and more.</li> </ol>"},{"location":"data_ingestion/#what-happens-under-the-hood","title":"What happens under the hood?","text":"<p>We use dlt as a loader to ingest data into the cognee metadata store. We can ingest data from various sources like SQL databases, REST APIs, OpenAPI specs, and cloud storage. This enables us to have a common data model we can then use to build models and pipelines. The models and pipelines we build in this way end up in the cognee data store, which is a unified interface to access the data.</p>"},{"location":"local_models/","title":"Running cognee with local models","text":""},{"location":"local_models/#getting-started-with-local-models","title":"\ud83d\ude80 Getting Started with Local Models","text":"<p>You'll need to run the local model on your machine or use one of the providers hosting the model.</p> <p>We had some success with mixtral, but 7b models did not work well. We recommend using mixtral for now.</p>"},{"location":"local_models/#ollama","title":"Ollama","text":"<p>Set up Ollama by following instructions on Ollama website</p> <p>Set the environment variable in your .env to use the model</p> <p><pre><code>LLM_PROVIDER = 'ollama'\n</code></pre> Otherwise, you can set the configuration for the model:</p> <p><pre><code>cognee.config.llm_provider = 'ollama'\n</code></pre> You can also set the HOST and model name:</p> <pre><code>cognee.config.llm_endpoint = \"http://localhost:11434/v1\"\ncognee.config.llm_model = \"mistral:instruct\"\n</code></pre>"},{"location":"local_models/#anyscale","title":"Anyscale","text":"<p><pre><code>LLM_PROVIDER = 'custom'\n</code></pre> Otherwise, you can set the configuration for the model:</p> <p><pre><code>cognee.config.llm_provider = 'custom'\n</code></pre> You can also set the HOST  and model name: <pre><code>LLM_MODEL = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\nLLM_ENDPOINT = \"https://api.endpoints.anyscale.com/v1\"\nLLM_API_KEY = \"your_api_key\"\n</code></pre></p> <p>You can set the same way HOST and model name for any other provider that has an API endpoint.</p>"},{"location":"pipelines/","title":"PIPELINES","text":"<p>Cognee uses tasks grouped into pipelines that populate graph and vector stores. These tasks analyze and enrich data, enhancing the quality of answers produced by Large Language Models (LLMs). </p> <p>The tasks are managed and executed asynchronously using the <code>run_tasks</code> and <code>run_tasks_parallel</code> functions.</p> <pre><code>pipeline = run_tasks(tasks, documents)\nasync for result in pipeline:\n    print(result)\n</code></pre>"},{"location":"pipelines/#main-pipeline-cogneecognify","title":"Main pipeline: cognee.cognify","text":"<p>This is the main pipeline currently implemented in cognee. It is designed to process data in a structured way and populate the graph and vector stores.</p> <p>This function is the entry point for processing datasets. It handles dataset retrieval, user authorization, and manages the execution of a pipeline of tasks that process documents.</p>"},{"location":"pipelines/#parameters","title":"Parameters","text":"<ul> <li><code>datasets: Union[str, list[str]] = None</code>: A string or list of dataset names to be processed.</li> <li><code>user: User = None</code>: The user requesting the processing. If not provided, the default user is retrieved.</li> </ul>"},{"location":"pipelines/#steps-in-the-function","title":"Steps in the Function","text":""},{"location":"pipelines/#user-authentication","title":"User Authentication","text":"<pre><code>if user is None:\n    user = await get_default_user()\n</code></pre> <p>If no user is provided, the function retrieves the default user.</p>"},{"location":"pipelines/#handling-empty-or-string-dataset-input","title":"Handling Empty or String Dataset Input","text":"<pre><code>existing_datasets = await get_datasets(user.id)\nif datasets is None or len(datasets) == 0:\n        datasets = existing_datasets\nif type(datasets[0]) == str:\n        datasets = await get_datasets_by_name(datasets, user.id)\n</code></pre> <p>If no datasets are provided, the function retrieves all datasets owned by the user. If a list of dataset names (strings) is provided, they are converted into dataset objects.</p>"},{"location":"pipelines/#selecting-datasets-from-the-input-list-that-are-owned-by-the-user","title":"Selecting datasets from the input list that are owned by the user","text":"<pre><code>existing_datasets_map = {\n        generate_dataset_name(dataset.name): True for dataset in existing_datasets\n    }\n</code></pre>"},{"location":"pipelines/#run-cognify-pipeline-for-each-dataset","title":"Run Cognify Pipeline for Each Dataset","text":"<p>```python awaitables = []</p> <p>for dataset in datasets:     dataset_name = generate_dataset_name(dataset.name)</p> <pre><code>if dataset_name in existing_datasets_map:\n    awaitables.append(run_cognify_pipeline(dataset, user))\n</code></pre> <p>return await asyncio.gather(*awaitables)</p> <p>The <code>run_cognify_pipeline</code> function is defined within <code>cognify</code> and is responsible for processing a single dataset. This is where most of the heavy lifting occurs. The function processes multiple datasets concurrently using <code>asyncio.gather</code>.</p>"},{"location":"pipelines/#pipeline-tasks","title":"Pipeline Tasks","text":"<p>The pipeline consists of several tasks, each responsible for different parts of the processing:</p> <ul> <li><code>classify_documents</code>: Converts each of the documents into one of the specific Document types: PdfDocument, AudioDocument, ImageDocument or TextDocument</li> <li><code>check_permissions_on_documents</code>: Checks if the user has the necessary permissions to access the documents. In this case, it checks for \"write\" permission.</li> <li><code>extract_chunks_from_documents</code>: Extracts text chunks based on the document type.</li> <li><code>add_data_points</code>: Creates nodes and edges from the chunks and their properties. Adds them to the graph engine.</li> <li><code>extract_graph_from_data</code>: Generates knowledge graphs from the document chunks.</li> <li><code>summarize_text</code>: Extracts a summary for each chunk using an llm.</li> </ul>"},{"location":"quickstart/","title":"QUICKSTART","text":"<p>To understand how cognee works check out the conceptual overview</p>"},{"location":"quickstart/#setup","title":"Setup","text":"<p>To run cognee, you will need the following:</p> <ol> <li>OpenAI API key (Ollama or Anyscale could work as well)</li> </ol> <p>Add your LLM API key to the environment variables</p> <p><pre><code>import os\n\nos.environ[\"LLM_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n</code></pre> or  <pre><code>cognee.config.llm_api_key = \"YOUR_OPENAI_API_KEY\"\n</code></pre> If you are using Networkx, create an account on Graphistry to visualize results: <pre><code>    cognee.config.set_graphistry_config({\n        \"username\": \"YOUR_USERNAME\",\n        \"password\": \"YOUR_PASSWORD\"\n    })\n</code></pre></p> <p>If you want to run Postgres instead of Sqlite, run postgres Docker container. Navigate to cognee folder and run: <pre><code>docker compose up postgres\n</code></pre></p> <p>Add the following environment variables to .env file <pre><code>DB_HOST=127.0.0.1\nDB_PORT=5432\nDB_USERNAME=cognee # or any username you want\nDB_PASSWORD=cognee # or any password you want\nDB_NAME=cognee_db # or any db name you want\nDB_PROVIDER=postgres\n</code></pre></p>"},{"location":"quickstart/#run","title":"Run","text":"<p>cognee is asynchronous by design, meaning that operations like adding information, processing it, and querying it can run concurrently without blocking the execution of other tasks.  Make sure to await the results of the functions that you call.</p> <pre><code>import cognee\n\ntext = \"\"\"Natural language processing (NLP) is an interdisciplinary\n       subfield of computer science and information retrieval\"\"\"\n\nawait cognee.add(text) # Add a new piece of information\n\nawait cognee.cognify() # Use LLMs and cognee to create knowledge\n\nsearch_results = await cognee.search(SearchType.INSIGHTS, query_text='Tell me about NLP')  # Query cognee for the knowledge\n\nfor result_text in search_results:\n    print(result_text)\n</code></pre> <p>In the example above, we add a piece of information to cognee, use LLMs to create a GraphRAG, and then query cognee for the knowledge. cognee is composable and you can build your own cognee pipelines using our templates.</p>"},{"location":"rags/","title":"Rags","text":""},{"location":"rags/#rag-stack","title":"RAG Stack","text":"<p>Core elements of a RAG stack are the building blocks that we can use to get to more personalized and deterministic outputs. </p> <p>This is a work in progress and any feedback is welcome</p>"},{"location":"rags/#what-is-a-rag","title":"What is a RAG?","text":"<p>What is RAG?</p> <p>RAG stands for Retrieval Augmented Generation. It is a model that combines the power of large language models (LLMs) like GPT-4 with the efficiency of information retrieval systems. The goal of RAG is to generate text that is both fluent and factually accurate by retrieving relevant information from a knowledge base.</p> <p>To try building a simple RAG and understand the limitations, check out this simple guide with examples: RAGs: Retrieval-Augmented Generation Explained</p>"},{"location":"rags/#the-building-blocks-of-a-rag-stack","title":"The Building Blocks of a RAG Stack","text":""},{"location":"rags/#1-data-sources","title":"1. Data Sources","text":"<p>You can get your data from a variety of sources, including:</p> <ul> <li>APIs like Twitter, Reddit, and Google</li> <li>Web scraping tools like Scrapy and Beautiful Soup</li> <li>Documents like PDFs, Word, and Excel files</li> <li>Relational databases like DuckDB, PSQL and MySQL</li> <li>Data warehouses like Snowflake and Databricks</li> <li>Customer data platforms like Segment</li> </ul> <p></p> Some data sources <p>The goal here is to give the data structure and connect it so that it can be used in your deterministic LLM stack.</p>"},{"location":"rags/#2-data-loaders","title":"2. Data Loaders","text":"Data Loaders <p>Data loading into a data lake or warehouse involves using tools like Apache Airflow, dlt, dbt, and Databricks. The process includes data extraction, transformation, and loading for model usage, aiming for a clean, structured dataset ready for enrichment. Check out how we do it with dlt: Data Loading Tool (dlt)</p>"},{"location":"rags/#3-vector-computation-and-vector-stores","title":"3. Vector Computation and Vector Stores","text":"<p>Data is transformed into vectors using OpenAI or custom models. Understanding where to run these models and integrating your computing infrastructure with tools like custom spark pipelines is essential. The aim is to achieve ready-to-use pipelines and models.</p> <p></p> Vector Stores  <p>Image Source</p>"},{"location":"rags/#4-graph-computation-and-graph-stores","title":"4. Graph Computation and Graph Stores","text":"<p>Creating a knowledge graph from your data allows for querying and information retrieval. It's essential to know how to construct, maintain, and use it for text generation. The aim is an accurate, current, and easily queried knowledge graph.</p> <p></p> Graph Example"},{"location":"rags/#5-search","title":"5. Search","text":"<p>The process involves querying and retrieving vectors from Vector DBs or hybrid DBs, and using search tools to rank these vectors. The aim is to index vectors and search for relevant ones as needed.</p>"},{"location":"rags/#vector-similarity-search","title":"Vector Similarity Search","text":"<p>Identifies objects with vector representations closest to the query vector, finding the most similar items based on various dimensions of comparison.</p>"},{"location":"rags/#image-search","title":"Image Search","text":"<p>Utilizes images as the input for conducting a similarity search, analyzing the content of the image to find similar images based on visual features.</p>"},{"location":"rags/#keyword-search","title":"Keyword Search","text":"<p>Employs the BM25F algorithm for ranking results based on keyword matches. Relevance is calculated using term frequency, inverse document frequency, and field-length normalization.</p>"},{"location":"rags/#hybrid-search","title":"Hybrid Search","text":"<p>Merges the BM25 algorithm with vector similarity search techniques to enhance the relevance and accuracy of search results. Leverages both textual and vector-based features for ranking.</p>"},{"location":"rags/#generative-search","title":"Generative Search","text":"<p>Utilizes the outputs of search results as prompts for a Large Language Model (LLM). Can generate summaries, extrapolations, or new content based on the aggregated search results.</p>"},{"location":"rags/#reranking","title":"Reranking","text":"<p>Involves the application of a reranker module to adjust the initial ranking of search results. Optimizes result relevance based on additional criteria or more complex models.</p>"},{"location":"rags/#aggregation","title":"Aggregation","text":"<p>Involves compiling and summarizing data from a set of search results. Provides insights or overviews based on the collective information found.</p>"},{"location":"rags/#filters","title":"Filters","text":"<p>Apply constraints or conditions to the search process to narrow down the results. Filters can be based on specific attributes, metadata, or other criteria relevant to the search domain.</p>"},{"location":"rags/#graph-search","title":"Graph Search","text":"<p>Involves traversing a graph data structure to find specific nodes or paths. It can be used to find relationships between different entities in a knowledge graph.</p>"},{"location":"research/","title":"Research","text":"<p>The page is dedicated to collecting all research that was collected in the past one year from various sources.</p> <p>This is not an exhaustive list, and any PRs would be welcome</p>"},{"location":"research/#research-papers","title":"Research Papers","text":"<ul> <li>2024/06/04(https://arxiv.org/abs/2402.01817)</li> <li>2024/06/04(https://arxiv.org/abs/2405.14992)</li> <li>2024/03/24(https://arxiv.org/abs/2404.07103)</li> <li>2024/03/24(https://arxiv.org/abs/2404.07143)</li> <li>2024/03/24(https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/)</li> <li>2015/07/30(https://arxiv.org/abs/1507.08539)</li> <li>[2023/12/12]  Dense X Retrieval: What Retrieval Granularity Should We Use?</li> <li>2024/01/05(https://arxiv.org/pdf/2312.10997.pdf)</li> <li>[2022/10/20]  Cognitive modelling with multilayer networks: Insights, advancements and future challenges</li> <li>[2023/09/20] CoAla framework and relevant literature literature</li> <li>2023/06/09(https://arxiv.org/pdf/2306.06070.pdf), Xiang Deng, et al.\u00a0[code] [demo]</li> <li>[2023/06/28] AI Agents in Langchain https://docs.google.com/presentation/d/1L_CHsg26sDxPmKj285Ob5T2xsAUejBlfiGQSnsSHTk0/edit#slide=id.g254e571859c_0_164</li> <li>[2023/06/27] Agent infra https://lilianweng.github.io/posts/2023-06-23-agent/</li> <li>2023/06/05(https://arxiv.org/pdf/2306.02707.pdf), Subhabrata Mukherjee et al.</li> <li>[2023/05/25]\u00a0\ud83d\udcdaVoyager: An Open-Ended Embodied Agent with Large Language Models, Guanzhi Wang, et al.\u00a0[code] [website], Shishir G. Patil, et al.</li> <li>[2023/05/24]\u00a0\ud83d\udcdaGorilla: Gorilla: Large Language Model Connected with Massive APIs</li> <li>[2023/05/17]\u00a0\ud83d\udcdaTree of Thoughts: Deliberate Problem Solving with Large Language Models, Shunyu Yao, et al.[code] [code-orig]</li> <li>[2023/05/12]\u00a0\ud83d\udcdaMEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers, Lili Yu, et al.</li> <li>[2023/05/09]\u00a0\ud83d\udcdaFrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance, Lingjiao Chen, et al.</li> <li>[2023/05/01]\u00a0\ud83d\udcdaLearning to Reason and Memorize with Self-Notes, Jack Lanchantin, et al.</li> <li>[2023/04/24]\u00a0\ud83d\udcdaWizardLM: Empowering Large Language Models to Follow Complex Instructions, Can Xu, et al.</li> <li>[2023/04/22]\u00a0\ud83d\udcdaLLM+P: Empowering Large Language Models with Optimal Planning Proficiency, Bo Liu, et al.</li> <li>[2023/04/07]\u00a0\ud83d\udcdaGenerative Agents: Interactive Simulacra of Human Behavior, Joon Sung Park, et al.\u00a0[code]</li> <li>2023/03/30(https://arxiv.org/abs/2303.17651), Aman Madaan, et al.[code]</li> <li>2023/03/30(https://arxiv.org/pdf/2303.17580.pdf), Yongliang Shen, et al.\u00a0[code] [demo]</li> <li>2023/03/20(https://arxiv.org/pdf/2303.11366.pdf), Noah Shinn , et al.\u00a0[code]</li> <li>[2023/02/23]\u00a0\ud83d\udcdaNot what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection, Sahar Abdelnab, et al.</li> <li>[2023/02/09]\u00a0\ud83d\udcdaToolformer: Language Models Can Teach Themselves to Use Tools, Timo Schick, et al.\u00a0[code]</li> <li>[2022/12/12]\u00a0\ud83d\udcdaLMQL: Prompting Is Programming: A Query Language for Large Language Models, Luca Beurer-Kellner, et al.</li> <li>2022/10/06(https://arxiv.org/pdf/2210.03629.pdf), Shunyu Yao, et al.\u00a0[code]</li> <li>[2022/07/12]\u00a0\ud83d\udcdaInner Monologue: Embodied Reasoning through Planning with Language Models, Wenlong Huang, et al.\u00a0[demo]</li> <li>2022/04/04(https://github.com/Significant-Gravitas/Nexus/wiki/Awesome-Resources), Michael Ahn, e al.\u00a0[demo]</li> <li>2021/12/17(https://arxiv.org/pdf/2112.09332.pdf), Reiichiro Nakano, et al.</li> <li>[2021/06/17]\u00a0\ud83d\udcdaLoRA: Low-Rank Adaptation of Large Language Models, Edward J. Hu, et al.</li> <li>2023/04/03(https://arxiv.org/abs/2304.03442)</li> <li>2023/05/17(https://arxiv.org/abs/2305.10601)ls</li> </ul>"},{"location":"research/#knowledge-graphs","title":"Knowledge Graphs","text":"<ul> <li>2023/06/09(https://www.brighttalk.com/webcast/9273/605659?utm_source=brighttalk-portal&amp;utm_medium=web&amp;utm_campaign=topic&amp;utm_content=upcoming)</li> </ul>"},{"location":"research/#blog-articles","title":"Blog Articles","text":"<ul> <li>2023/04/29(https://www.leewayhertz.com/autogpt/)\u00a0By Akash Takyar</li> <li>2023/04/20(https://pattern.swarma.org/article/230)\u00a0By Jiang Zhang</li> <li>2023/04/18(https://blog.langchain.dev/agents-round/)\u00a0By Langchain</li> <li>2023/04/16(https://towardsdatascience.com/4-autonomous-ai-agents-you-need-to-know-d612a643fa92)\u00a0By Sophia Yang</li> <li>2023/03/31(https://zhuanlan.zhihu.com/p/618448188)\u00a0By Haojie Pan</li> </ul>"},{"location":"research/#talks","title":"Talks","text":"<ul> <li>2023/06/05(https://www.youtube.com/watch?v=rGgGOccMEiY&amp;t=1497s)\u00a0by Geoffrey Hinton</li> <li>2023/05/24(https://www.youtube.com/watch?v=bZQun8Y4L2A)\u00a0by Andrej Karpathy | OpenAI</li> <li>[2024/03/15] Podcast on AI, Memory by Bill Gurley</li> </ul>"},{"location":"search/","title":"Explore data","text":""},{"location":"search/#cognee-search-module","title":"Cognee Search Module","text":"<p>This module contains the search function that is used to search for nodes in the graph. It supports various search types and integrates with user permissions to filter results accordingly.</p>"},{"location":"search/#search-types","title":"Search Types","text":"<p>The <code>SearchType</code> enum defines the different types of searches that can be performed:</p> <ul> <li><code>INSIGHTS</code>: Search for insights from the knowledge graph.</li> <li><code>SUMMARIES</code>: Search for summaries of the texts provided.</li> <li><code>CHUNKS</code>: Search for the whole chunks of data.</li> </ul>"},{"location":"search/#search-function","title":"Search Function","text":"<p>The <code>search</code> function is the main entry point for performing a search. It handles user authentication, retrieves document IDs for the user, and filters the search results based on user permissions.</p> <pre><code>from cognee import search, SearchType\nawait search(SearchType.INSIGHTS, \"your_query\")\n</code></pre>"},{"location":"team/","title":"Team","text":""},{"location":"why/","title":"Why use cognee?","text":"<p>cognee is one of the first OSS tools that enables easy, scalable and flexible use of LLMs to process large volumes of documents using GraphRAG approach. </p> <p>LLMs don't have a semantic layer, and they don't have a way to understand the data they are processing. This is where cognee comes in.  We let you define logical structures for your data and then use these structures to guide the LLMs to process the data in a way that makes sense to you.</p> <p>cognee helps you avoid the overly complicated set of tools and processes to give you somewhat reliable output</p> <p>From</p> <p></p> <p>To</p> <p></p> Why use cognee? <p>Its hard to answer the question of why use cognee without answering why you need thin LLM frameworks in the first place.:)</p> <ul> <li>Cost-effective \u2014 cognee extends the capabilities of your LLMs without the need for expensive data processing tools.</li> <li>Self-contained \u2014 cognee runs as a simple-to-use library meaning you can add it to your application easily</li> <li>Easy to use \u2014 Navigate graphs instead of embeddings to understand your data faster and better</li> <li>Flexible \u2014 cognee lets you control your input and provide your own Pydantic data models.</li> </ul>"},{"location":"concepts/graph_data_models/","title":"Graph data models","text":"<p>Graph data models are fundamental structures used to represent and store data in the form of graphs, which consist of nodes (or vertices) and edges (or links). This model is particularly effective for illustrating relationships and connections among various data entities, making it invaluable in domains such as social networks, recommendation systems, logistics, biological networks, and more. Here's an overview of key concepts and types of graph data models:</p> <p>Key Concepts: Nodes (Vertices): Represent entities or objects within the graph, such as people in a social network, stations in a transportation map, or proteins in biological networks. Edges (Links): Depict the relationships or interactions between nodes. Edges can be directed (indicating a one-way relationship) or undirected (indicating a mutual relationship). Properties: Both nodes and edges can have properties (key-value pairs) that provide additional information, such as weights, types, or other attributes relevant to the application.</p>"},{"location":"concepts/llm_structured_outputs/","title":"Llm structured outputs","text":"<p>Function calling in the context of Large Language Models (LLMs) like GPT-3, GPT-4, and their derivatives extends beyond traditional programming paradigms. In this scenario, function calling involves prompting the LLM to simulate the behavior of a function within its generated output. This capability allows users to interact with LLMs in a structured way, effectively requesting specific operations or information retrieval tasks by framing their prompts as function calls.</p> <p>How LLM Function Calling Works: Prompt Construction: The user constructs a prompt that mimics a function call in programming. This prompt includes the \"name\" of the function (often a description of the task) and the \"arguments\" (the specific inputs or conditions for the task). For example, a prompt might look like \"Generate a summary for the following article:\" followed by the article text.</p> <p>LLM Interpretation: The LLM interprets this structured prompt and understands it as a request to perform a specific task, similar to how a function in a program would be invoked. The model then generates an output that aligns with the expected behavior of the function described in the prompt.</p> <p>Parameters and Outputs: In LLM function calling, the parameters are the details provided in the prompt, and the output is the generated text that the model produces in response. This output is intended to fulfill the function's \"purpose\" as inferred from the prompt.</p>"},{"location":"concepts/multilayer_graph_networks/","title":"Multilayer graph networks","text":"<p>A multilayer graph network is a sophisticated structure used to model complex systems where entities and their interactions can exist in multiple layers, each representing a different type of relationship, context, or domain. Unlike traditional graphs that capture connections in a single, uniform setting, multilayer graphs provide a more nuanced framework, allowing for the representation of diverse interconnections and dependencies across various dimensions or layers. </p>"},{"location":"concepts/propositions/","title":"Propositions","text":"<p>Propositions are fundamental elements in the study of logic, linguistics, and natural language processing. They represent atomic expressions within texts that encapsulate distinct factoids, conveying specific pieces of information. In essence, a proposition is a declarative statement that can either be true or false, but not both simultaneously. This binary nature makes propositions crucial for logical deductions, reasoning, and the construction of arguments.</p> <p>In a natural language context, propositions are presented in a concise and self-contained format.  They are designed to convey information clearly and unambiguously, making them easily interpretable by humans and computable by machines. For example, the statement \"The Eiffel Tower is in Paris\" is a proposition because it presents a specific fact about the location of the Eiffel Tower, and its truth value can be assessed as either true or false.</p> <p>The concept of propositions extends beyond mere statements of fact to include assertions about concepts, relationships, and conditions.  For instance, \"If it rains, the ground gets wet\" is a conditional proposition that establishes a cause-and-effect relationship between two events.</p> <p>In computational linguistics and natural language processing, propositions are vital for tasks such as information extraction, knowledge representation, and question answering.</p>"}]}